##naive bayes for regression
naive bayes是很簡單的方法,但是在分類問題的許多情況中,經常比一些更複雜的方法來得精確。
雖然naive bayes對於機率的估計不是那麼精確,不過在找出最大機率這個問題上,通常都會正確。
也就是說他的絕對機率通常不會太準,不過相對機率是準的。

但是在預測數值(numberic prediction,ex:regression)這種問題類型時,naive bayes的效果就不知道有沒有像在分類問題上來得精確,
作者猜測naive bayes在回歸的結果不會太好,因為`naive bayes對於機率的估計不是那麼準確。`
作者實際檢驗之後,在實際的情況,naive bayes普偏比locally weighted linear regression,model tress的效果來得差
就算使用標準的naive bayes(把數值切成好幾個區間)來處理回歸問題,效果也沒有很好。

作者又做了一些實驗,發現了naive bayes的獨立假設,(也就是所有input都是獨立)是他在regression上表現差的主要原因。也就是說獨立假設在regression問題比classification問題限制更多。

naive bayes在在實際的分類問題,獨立假設的效果(也就是獨立假設不成真,所以預測的效果會很糟)沒有像我們想像中那麼嚴重。

####locally weighted linear regression
loess
你給一個test data,x可能是k維度
從train data找到最靠近x的data
使用一階或是2階的polymeral

###schoolsdata.txt
八個學校接受一個考試
有上課再去考試與沒有上課就去考試的分數差就是estimate
sd則是分數的標準差

\\(
\hat{\theta}_j=\lambda_jy_j+(1-\lambda_j)\bar{y}
\\)

###The Full Bayesian approach
hierarchical normal model 也稱為one-way normal random-effect model


使用grid來離散近似tau的事後分配
###作業
看p600~601

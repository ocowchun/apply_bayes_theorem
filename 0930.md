##0930

###12月要報告 
topicmodel
交代模型的部分

Blei DM, Ng AY, Jordan MI (2003b). “Latent Dirichlet Allocation.” Journal of Machine Learning Research, 3, 993–1022.

###LDA(latent Dirichelt allocation)

###Limiting Probabilities極限機率
\\(
\large \pi_j=\sum\limits_{i=0}^{1} \pi_{i}P_{ij}
\\)

\\(
\large \pi_0=\pi_{0}P_{00}+\pi_{1}P_{10}
\\)

\\(
\large \pi_1=\pi_{0}P_{01}+\pi_{1}P_{11}
\\)


在系統穩定的情況下:
狀態為0的機率為\\( \pi_0\\)也就是說:

time=n,在狀態0的機率為 \\( \pi_0\\)

time=n+1,在狀態0的機率為 \\( \pi_0\\)

\\(x_n分配與x_{n+1}分配會相同\\)

也就是\\(P(x_{n+1}=0)=P(x_n=0)=\pi_0\\)

\\(
\pi_0=P(x_{n+1}=0)=P(x_{n+1}=0,x_n=0)+P(x_{n+1}=0,x_n=1)
\\)

又
\\(
P(x_{n+1}=0,x_n=0) = P(x_n=0)P(x_{n+1}=0|x_n=0)= \pi_{0}P_{00}
\\)

\\(
P(x_{n+1}=0,x_n=1) = P(x_n=1)P(x_{n+1}=0|x_n=1)= \pi_{1}P_{10}
\\)


所以
\\(
\large \pi_0=\pi_{0}P_{00}+\pi_{1}P_{10}
\\)


系統穩定就是分配相同的意思，系統穩定時，\\(x_n\\)的分配就是極限分配也就是你的目標分配。


####stationary probabilities(平穩機率)
\\(\pi_j\\)通常稱為stationary probabilities 也就是系統進入穩定後，狀態為j的機率。

####markov chain
下一刻狀態只跟現在狀態有關

###ergodic


###何謂Time reversible(時間可逆)
\\(P_{ij}\\)為時間序列的移轉機率

\\(Q_{ij}\\)為時間序列反過來看的移轉機率

當\\(Q_{ij}=P_{ij}\\)稱之為時間可逆

如果存在非負整數(\\(\pi_0,pi_1....\\))，總和等於1，並滿足時間可逆
\\(
( \pi_jP_{ji} = \pi_iP_{ij} )
\\)則:

1. Markov chain 是時間可逆
2. 這些數字(\\(\pi_0,\pi_1....\\))就是這組時間序列的limiting probabilities(極限機率)，這組機率條件會組成極限分配

時間夠大時，狀態機率與起始值無關，只與當前的狀態有關。

###問題
####什麼是事後分配?

####conjugate共軛分配
如果事前與事後的分配是相同家族，則稱之為共軛分配

####hyperparamerter
事前分配的參數


###作業
1. 模擬
\\(
 Q_{ij}=\pi_{j}P_{ij}/\pi_{i}
 \\)

2. gamma與inverse gamma的分配，還有他們的pdf要怎麼推導 with 敏勝